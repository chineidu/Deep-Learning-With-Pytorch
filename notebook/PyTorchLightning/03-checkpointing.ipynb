{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Sequence, TypeAlias, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_up_from_current_directory(go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "polars      : 0.20.18\n",
      "scikit-learn: 1.4.1.post1\n",
      "torch       : 2.2.2\n",
      "lightning   : 2.2.1\n",
      "\n",
      "Torch CUDA available?:  False\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from watermark import watermark\n",
    "\n",
    "Model: TypeAlias = nn.Module\n",
    "\n",
    "print(watermark(packages=\"polars,scikit-learn,torch,lightning\", python=True))\n",
    "print(\"Torch CUDA available?: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lightning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(L.LightningModule):\n",
    "    def __init__(self, model: nn.Module, learning_rate: float) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.val_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "        self.test_accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "\n",
    "        self.save_hyperparameters(ignore=[\"model\"])\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def _shared_steps(self, batch) -> torch.Tensor:\n",
    "        # Fetch the data\n",
    "        features, true_labels = batch\n",
    "\n",
    "        # Forward prop\n",
    "        logits: torch.Tensor = self(features)\n",
    "        predited_labels: torch.Tensor = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss: torch.Tensor = F.cross_entropy(logits, true_labels)\n",
    "\n",
    "        return loss, true_labels, predited_labels\n",
    "\n",
    "    def training_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        # Shared steps\n",
    "        loss, true_labels, predited_labels = self._shared_steps(batch=batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        self.train_accuracy(true_labels, predited_labels)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\n",
    "            \"train_accuracy\",\n",
    "            self.train_accuracy,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        # Shared steps\n",
    "        loss, true_labels, predited_labels = self._shared_steps(batch=batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        self.val_accuracy(true_labels, predited_labels)\n",
    "\n",
    "        # Log loss and accuracy\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\n",
    "            \"val_accuracy\",\n",
    "            self.val_accuracy,\n",
    "            prog_bar=True,\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx) -> torch.Tensor:\n",
    "        # Shared steps\n",
    "        loss, true_labels, predited_labels = self._shared_steps(batch=batch)\n",
    "\n",
    "        # Compute accuracy\n",
    "        self.test_accuracy(true_labels, predited_labels)\n",
    "\n",
    "        # Log accuracy\n",
    "        self.log(\"test_accuracy\", self.test_accuracy)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> Any:\n",
    "        optimizer: Any = torch.optim.SGD(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "NDArray: TypeAlias = npt.NDArray[np.float_ | np.int_]\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, features: torch.Tensor, labels: torch.Tensor, transform: Any | None = None\n",
    "    ) -> None:\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.4359949 , 0.02592623, 0.54966248],\n",
       "        [0.43532239, 0.4203678 , 0.33033482],\n",
       "        [0.20464863, 0.61927097, 0.29965467],\n",
       "        [0.26682728, 0.62113383, 0.52914209],\n",
       "        [0.13457995, 0.51357812, 0.18443987]]),\n",
       " array([1, 0, 0, 1, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "X: NDArray = np.random.rand(5, 3)\n",
    "y: NDArray = np.random.choice(a=[0, 1], size=5)\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">getter: <span style=\"font-weight: bold\">(</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4360</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0259</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5497</span><span style=\"font-weight: bold\">])</span>, <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">))</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "getter: \u001b[1m(\u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.4360\u001b[0m, \u001b[1;36m0.0259\u001b[0m, \u001b[1;36m0.5497\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m, \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_dataset: CustomDataset = CustomDataset(features=X, labels=y)\n",
    "console.print(f\"getter: {my_dataset[0]}\")\n",
    "console.print(f\"length: {len(my_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lightning Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class LitDataModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir: str = \"../../data/classification_data.csv\",\n",
    "        batch_size: int = 32,\n",
    "        seed: int = 123,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.seed = seed\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        \"\"\"This optional method is used to download the data.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        # Create data\n",
    "        X, y = make_classification(\n",
    "            n_samples=20_000,\n",
    "            n_classes=2,\n",
    "            n_features=100,\n",
    "            n_informative=10,\n",
    "            n_redundant=40,\n",
    "            n_repeated=25,\n",
    "            n_clusters_per_class=5,\n",
    "            flip_y=0.05,\n",
    "            class_sep=0.5,\n",
    "            random_state=123,\n",
    "        )\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=self.seed, stratify=y\n",
    "        )\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.1, random_state=self.seed, stratify=y_train\n",
    "        )\n",
    "        self.train_dataset = CustomDataset(features=X_train, labels=y_train)\n",
    "        self.val_dataset = CustomDataset(features=X_val, labels=y_val)\n",
    "        self.test_dataset = CustomDataset(features=X_test, labels=y_test)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            drop_last=True,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.val_dataset, batch_size=self.batch_size, shuffle=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            dataset=self.test_dataset, batch_size=self.batch_size, shuffle=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, num_features: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.all_layers = nn.Sequential(\n",
    "            # 1st hidden layer\n",
    "            nn.Linear(num_features, 64),\n",
    "            nn.ReLU(),\n",
    "            # 2nd hidden layer\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            # Output layer\n",
    "            nn.Linear(32, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = torch.flatten(input=x, start_dim=1)\n",
    "        logits: torch.Tensor = self.all_layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(seed=123)\n",
    "\n",
    "data_module: LitDataModule = LitDataModule()\n",
    "# Lightning Model\n",
    "pytorch_model = MLP(num_features=100, num_classes=2)\n",
    "lightning_model: LitModel = LitModel(model=pytorch_model, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "callbacks: list[Any] = [\n",
    "    ModelCheckpoint(\n",
    "        save_top_k=3,  # save top k models based on monitor metric\n",
    "        monitor=\"val_accuracy\",  # monitor quantity for model checkpointing\n",
    "        mode=\"max\",  # use \"max\" or \"min\". i.e save the model with the best monitored quantity\n",
    "        save_last=True,  # whether to save last model\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: logs/my-model\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | model          | MLP                | 8.6 K \n",
      "1 | train_accuracy | MulticlassAccuracy | 0     \n",
      "2 | val_accuracy   | MulticlassAccuracy | 0     \n",
      "3 | test_accuracy  | MulticlassAccuracy | 0     \n",
      "------------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f19336277fd471d98e15e9b2ef40267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7873ee15e04c423790db21408d7f7164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447dc71aed4e4ecd9751ef2c9796b0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f938c206c9cd498a8fabe2e44edaad83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8278e19ffd4d39bbc46c5d5d807ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c49cd25144462384ec590f90b6f17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e4feaedac54584b97a0143088114f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e244716617c14054a0e9b53971f3e2cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5b548a704a47bc9bd69a2afd5e7a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d5d5ff8f5d460da86a4211468ce101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42209ccef0834af48a21e08845f2c484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "\n",
    "# Logger\n",
    "logger = CSVLogger(save_dir=\"logs/\", name=\"my-model\")\n",
    "\n",
    "# Trainer\n",
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    max_epochs=10,\n",
    "    deterministic=True,\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "# Fit\n",
    "trainer.fit(model=lightning_model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_up_from_current_directory(go_up=2)\n",
    "from src.helper_plotting import plot_csv_logger\n",
    "\n",
    "\n",
    "plot_csv_logger(csv_path=f\"{trainer.logger.log_dir}/metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Best Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=lightning_model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(\n",
    "    model=lightning_model,\n",
    "    datamodule=data_module,\n",
    "    ckpt_path=\"best\",  # optional, path to best checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(\n",
    "    model=lightning_model,\n",
    "    datamodule=data_module,\n",
    "    ckpt_path=\"last\", # load the last checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path: str = trainer.checkpoint_callback.best_model_path\n",
    "\n",
    "lightning_model = LitModel.load_from_checkpoint(path, model=pytorch_model)\n",
    "lightning_model.eval()\n",
    "\n",
    "trainer.test(model=lightning_model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
