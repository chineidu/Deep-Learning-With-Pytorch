{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in library\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "from typing import Any, Optional, Sequence, Union\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"info\": \"#76FF7B\",\n",
    "        \"warning\": \"#FBDDFE\",\n",
    "        \"error\": \"#FF0000\",\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.8\n",
      "IPython version      : 8.22.2\n",
      "\n",
      "numpy       : 1.26.4\n",
      "pandas      : 2.2.1\n",
      "matplotlib  : 3.8.3\n",
      "torch       : 2.2.2\n",
      "lightning   : 2.2.1\n",
      "scikit-learn: 1.4.1.post1\n",
      "\n",
      "conda environment: torch_p11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -p numpy,pandas,matplotlib,torch,lightning,scikit-learn --conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fp: str = \"../../data/titanic/train_features.parquet\"\n",
    "train_fp1: str = \"../../data/titanic/train_target.parquet\"\n",
    "test_fp: str = \"../../data/titanic/test_features.parquet\"\n",
    "test_fp1: str = \"../../data/titanic/test_target.parquet\"\n",
    "\n",
    "train_df: pl.DataFrame = pl.read_parquet(train_fp)\n",
    "train_target_df: pl.DataFrame = pl.read_parquet(train_fp1)\n",
    "test_df: pl.DataFrame = pl.read_parquet(test_fp)\n",
    "test_target_df: pl.DataFrame = pl.read_parquet(test_fp1)\n",
    "\n",
    "train_df.shape, train_target_df.shape, test_df.shape, test_target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data: pl.DataFrame = pl.concat([train_df, train_target_df], how=\"horizontal\")\n",
    "X: pd.DataFrame = data.to_pandas().drop(columns=[\"survived\"])\n",
    "y: pd.Series = data.to_pandas()[\"survived\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "console.print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train: npt.NDArray[np.float_ | np.int_] = y_train.values.reshape(-1, 1)\n",
    "y_val: npt.NDArray[np.float_ | np.int_] = y_val.values.reshape(-1, 1)\n",
    "\n",
    "console.print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 1D smoothing filter\n",
    "def smooth(x, k=5):\n",
    "    \"\"\"This is used to smoothen the plot\"\"\"\n",
    "    return np.convolve(x, np.ones(k) / k, mode=\"same\")\n",
    "\n",
    "\n",
    "def visualize_accuracy_n_loss(\n",
    "    *, accuracy: Union[Sequence, np.ndarray], losses: torch.Tensor | list[float]\n",
    ") -> None:\n",
    "    \"\"\"This is used to visualize the accuracy and loss per training epoch.\"\"\"\n",
    "    if isinstance(losses, list):\n",
    "        losses = torch.tensor(losses)\n",
    "\n",
    "    _, axs = plt.subplots(1, 2, figsize=(8, 6))\n",
    "\n",
    "    axs[0].plot(smooth(losses.detach()))\n",
    "    axs[0].set(xlabel=\"Epochs\", ylabel=\"Training Loss\", title=\"Losses\")\n",
    "\n",
    "    axs[1].plot(smooth(accuracy))\n",
    "    axs[1].set(xlabel=\"Epochs\", ylabel=\"Accuracy\", title=\"Accuracy\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size) -> None:\n",
    "        super().__init__()\n",
    "        # Hidden layer 1\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Hidden layer 2\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Output layer\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    *,\n",
    "    model: nn.Module,\n",
    "    learning_rate: float,\n",
    "    epochs: int,\n",
    "    X_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    display_loss: bool = False,\n",
    "):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = torch.zeros(size=(epochs,))\n",
    "    accuracy = torch.zeros(size=(epochs,))\n",
    "\n",
    "    for epoch_id in tqdm(range(epochs)):\n",
    "        # Reset the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward propagtion\n",
    "        y_pred: torch.Tensor = model(X_train)\n",
    "        # Compute loss\n",
    "        loss: torch.Tensor = criterion(y_pred, y_train)\n",
    "        losses[epoch_id] = loss\n",
    "        # Calculate accuracy\n",
    "        accuracy[epoch_id] = (\n",
    "            (y_pred > 0.5).float() == y_train.float()\n",
    "        ).sum() / y_train.size(0)\n",
    "\n",
    "        # Back propagation\n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        if display_loss:\n",
    "            if (epoch_id + 1) % 100 == 0:\n",
    "                console.print(f\"Epoch [{epoch_id+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model, losses, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(torch.tensor(0.8) > 0.6)  # .float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "batch_size: int = 16\n",
    "# Create datasets\n",
    "train_dataset: TensorDataset = TensorDataset(\n",
    "    torch.tensor(X_train.to_numpy()).float(),\n",
    "    torch.tensor(y_train).float(),\n",
    ")\n",
    "val_dataset: TensorDataset = TensorDataset(\n",
    "    torch.tensor(X_val.to_numpy()).float(),\n",
    "    torch.tensor(y_val).float(),\n",
    ")\n",
    "\n",
    "train_dataloader: DataLoader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader: DataLoader = DataLoader(\n",
    "    dataset=val_dataset, batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader.dataset.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y: torch.Tensor = torch.Tensor([[0.45, 0.55], [0.7, 0.3]])\n",
    "torch.argmax(y, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    *,\n",
    "    model: nn.Module,\n",
    "    learning_rate: float,\n",
    "    epochs: int,\n",
    "    train_dataloader: DataLoader,\n",
    "    validation_dataloader: DataLoader,\n",
    "    display_loss: bool = False,\n",
    "):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    training_losses: list[float] = []\n",
    "    val_losses: list[float] = []\n",
    "\n",
    "    training_accuracy: list[float] = []\n",
    "    val_accuracy: list[float] = []\n",
    "\n",
    "    for epoch_id in tqdm(range(epochs)):\n",
    "        batch_losses: list[float] = []\n",
    "        batch_accuracy: list[float] = []\n",
    "\n",
    "        for X_t, y_tr in train_dataloader:\n",
    "            # Reset the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagtion\n",
    "            y_proba: torch.Tensor = model(X_t)\n",
    "\n",
    "            # Compute batch loss\n",
    "            loss: torch.Tensor = criterion(y_proba, y_tr)\n",
    "            batch_losses.append(loss.detach().numpy())\n",
    "\n",
    "            # Back propagation\n",
    "            loss.backward()\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute batch accuracy\n",
    "            y_pred: torch.Tensor = torch.argmax(y_proba, axis=1)\n",
    "            batch_acc = torch.mean((y_pred == y_tr).float()) * 100\n",
    "            batch_accuracy.append(batch_acc.detach().numpy())\n",
    "\n",
    "        # Training loss and accuracy\n",
    "        training_losses.append(np.mean(batch_losses))\n",
    "        training_accuracy.append(np.mean(batch_accuracy))\n",
    "\n",
    "        # Validation\n",
    "        X_val, y_val = next(iter(validation_dataloader))\n",
    "        y_proba_val: torch.Tensor = model(X_val)\n",
    "        y_pred_val: torch.Tensor = torch.argmax(y_proba_val, axis=1)\n",
    "\n",
    "        # Loss\n",
    "        val_loss: torch.Tensor = criterion(y_proba_val, y_val)\n",
    "        val_acc: torch.Tensor = torch.mean((y_pred_val == y_val).float())\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracy.append(val_acc)\n",
    "\n",
    "        if display_loss:\n",
    "            if (epoch_id + 1) % 100 == 0:\n",
    "                console.print(f\"Epoch [{epoch_id+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model, training_losses, training_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs: int = 100\n",
    "learning_rate: float = 0.01\n",
    "model = TitanicClassifier(input_size=11)\n",
    "\n",
    "\n",
    "model, training_losses, training_accuracy, val_accuracy = train_model(\n",
    "    model=model,\n",
    "    learning_rate=learning_rate,\n",
    "    epochs=epochs,\n",
    "    train_dataloader=train_dataloader,\n",
    "    validation_dataloader=val_dataloader,\n",
    ")\n",
    "\n",
    "console.print(f\"Training accuracy: {np.mean(training_accuracy):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.print(np.min(training_losses), np.max(training_losses))\n",
    "console.print(np.min(training_accuracy), np.max(training_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_accuracy_n_loss(accuracy=training_accuracy, losses=training_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test: torch.Tensor = torch.Tensor(test_df.to_numpy()).float()\n",
    "y_test: torch.Tensor = torch.Tensor(test_target_df.to_numpy()).float()\n",
    "\n",
    "y_proba: torch.Tensor = model(X_test)\n",
    "y_pred = (y_proba > 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "\n",
    "acc_score = accuracy_score(y_test.reshape(-1, 1), y_pred)\n",
    "auc_score = roc_auc_score(y_test.reshape(-1, 1), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
