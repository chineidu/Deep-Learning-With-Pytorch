{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chineidu/Deep-Learning-With-Pytorch/blob/main/notebook/08_FFN_Autoencoders/03_CPUs_vs_GPUs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrfybMdFTEJx"
      },
      "source": [
        "# CPU Vs GPU\n",
        "\n",
        "```text\n",
        "CPU\n",
        "---\n",
        "- Designed for sequential processing.\n",
        "Used for ML tasks that don't require a lot of parallel processing power. e.g. data preprocwssing, feature extraction and model evaluation.\n",
        "- It's cheaper than GPUs.\n",
        "\n",
        "\n",
        "GPU\n",
        "---\n",
        "- Designed for parallel processing.\n",
        "- Used for ML tasks such as training neural networks.\n",
        "- It's more expensive than CPUs.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_sAQxJJmTEJ0"
      },
      "outputs": [],
      "source": [
        "# Built-in library\n",
        "import logging\n",
        "from typing import Any, Optional, Sequence, Union\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configure the backend\n",
        "import matplotlib_inline.backend_inline\n",
        "\n",
        "# Pandas settings\n",
        "pd.options.display.max_rows = 1_000\n",
        "pd.options.display.max_columns = 1_000\n",
        "pd.options.display.max_colwidth = 2_000\n",
        "\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
        "import seaborn as sns\n",
        "\n",
        "# Custom import\n",
        "# from src.utilities import (\n",
        "#     set_up_logger,\n",
        "#     create_iris_data,\n",
        "#     create_qwerties_data,\n",
        "#     smooth,\n",
        "# )\n",
        "# from src.data_manager import (\n",
        "#     load_data,\n",
        "#     create_data_loader,\n",
        "#     split_into_train_n_validation,\n",
        "# )\n",
        "# from src.preprocessor import Standardizer, Normalizer\n",
        "\n",
        "\n",
        "# Black code formatter (Optional)\n",
        "# %load_ext lab_black\n",
        "# # auto reload imports\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select the processor device\n",
        "\n",
        "```text\n",
        "Note: To run models on a GPU you must select from the menu:\n",
        "  -> Runtime\n",
        "     -> Change runtime type\n",
        "       -> Hardware accelerator\n",
        "         -> GPU\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "Sj7yzvnxTEJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6R9J3MeTEJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wV_8xfcTEJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fak1u_ehTEJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YclQ7fvvTEJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAxgc5mkTEJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exPAg6GITEJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfJGHUpeTEJ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H8fb1ExTEJ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MFuOcimTEJ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPm_DjNBTEJ5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrbWAb7tTEJ5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}