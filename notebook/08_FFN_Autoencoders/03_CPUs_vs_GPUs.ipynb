{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chineidu/Deep-Learning-With-Pytorch/blob/main/notebook/08_FFN_Autoencoders/03_CPUs_vs_GPUs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrfybMdFTEJx"
      },
      "source": [
        "# CPU Vs GPU\n",
        "\n",
        "```text\n",
        "CPU\n",
        "---\n",
        "- Designed for sequential processing.\n",
        "Used for ML tasks that don't require a lot of parallel processing power. e.g. data preprocwssing, feature extraction and model evaluation.\n",
        "- It's cheaper than GPUs.\n",
        "\n",
        "\n",
        "GPU\n",
        "---\n",
        "- Designed for parallel processing.\n",
        "- Used for ML tasks such as training neural networks.\n",
        "- It's more expensive than CPUs.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_sAQxJJmTEJ0"
      },
      "outputs": [],
      "source": [
        "# Built-in library\n",
        "import logging\n",
        "from typing import Any, Optional, Sequence, Union\n",
        "\n",
        "# Standard imports\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configure the backend\n",
        "import matplotlib_inline.backend_inline\n",
        "\n",
        "# Pandas settings\n",
        "pd.options.display.max_rows = 1_000\n",
        "pd.options.display.max_columns = 1_000\n",
        "pd.options.display.max_colwidth = 2_000\n",
        "\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
        "import seaborn as sns\n",
        "\n",
        "# Custom import\n",
        "# from src.utilities import (\n",
        "#     set_up_logger,\n",
        "#     create_iris_data,\n",
        "#     create_qwerties_data,\n",
        "#     smooth,\n",
        "# )\n",
        "# from src.data_manager import (\n",
        "#     load_data,\n",
        "#     create_data_loader,\n",
        "#     split_into_train_n_validation,\n",
        "# )\n",
        "# from src.preprocessor import Standardizer, Normalizer\n",
        "\n",
        "\n",
        "# Black code formatter (Optional)\n",
        "# %load_ext lab_black\n",
        "# # auto reload imports\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select the processor device\n",
        "\n",
        "```text\n",
        "Note: To run models on a GPU you must select from the menu:\n",
        "  -> Runtime\n",
        "     -> Change runtime type\n",
        "       -> Hardware accelerator\n",
        "         -> GPU\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "Sj7yzvnxTEJ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6R9J3MeTEJ3",
        "outputId": "2e509c1a-759a-492d-941a-7d6d97159914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Use GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wV_8xfcTEJ3",
        "outputId": "9166cf62-770e-4ba7-e180-d7825835f59a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=20, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=500, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=500, out_features=30, bias=True)\n",
              "  (5): ReLU()\n",
              "  (6): Linear(in_features=30, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Build A Simple Model\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(20, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 500),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(500, 30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30, 2)\n",
        "      )\n",
        "\n",
        "net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fak1u_ehTEJ3"
      },
      "outputs": [],
      "source": [
        "# Create the test data\n",
        "X = torch.randn((1000, 20))\n",
        "y = torch.randint(low=0, high=2, size=(1, 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YclQ7fvvTEJ3"
      },
      "outputs": [],
      "source": [
        "# Send the model and the data to the GPU\n",
        "net.to(device)\n",
        "\n",
        "# data\n",
        "X = X.to(device)\n",
        "y = y.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "sHqBpxx5Bb9N",
        "outputId": "d783b138-af08-4f5a-dca2-85808a48f548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAxgc5mkTEJ3",
        "outputId": "ccd2dfd0-3aeb-4a4b-b16f-2cf60d917d87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "cuda:0\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# You can also create data directly on the GPU\n",
        "X_G = torch.randn((1000,20), device=device)\n",
        "X_C = torch.randn((1000,20), device='cpu')\n",
        "\n",
        "print(X.device)\n",
        "print(X_G.device)\n",
        "print(X_C.device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make Predictions\n",
        "y_pred = net(X)"
      ],
      "metadata": {
        "id": "TYrVdU-15nSM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.device"
      ],
      "metadata": {
        "id": "1AMQh1vG5nPz",
        "outputId": "6fde1a09-534f-4226-aa77-1851b6b9dece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the data. The data has to be sent to the CPU before it can be plotted.\n",
        "plt.plot(y_pred.detach().cpu());"
      ],
      "metadata": {
        "id": "de0_lLVg5nMs",
        "outputId": "0976ef13-cc04-48e0-938f-4971bba8a510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"409.165312pt\" height=\"297.190125pt\" viewBox=\"0 0 409.165312 297.190125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-06-17T20:26:25.153638</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 297.190125 \nL 409.165312 297.190125 \nL 409.165312 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 44.845313 273.312 \nL 401.965312 273.312 \nL 401.965312 7.2 \nL 44.845313 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m4713da7924\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m4713da7924\" x=\"61.07804\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(57.89679 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m4713da7924\" x=\"126.073945\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <g transform=\"translate(116.530195 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m4713da7924\" x=\"191.06985\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <g transform=\"translate(181.5261 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m4713da7924\" x=\"256.065755\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <g transform=\"translate(246.522005 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m4713da7924\" x=\"321.06166\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <g transform=\"translate(311.51791 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m4713da7924\" x=\"386.057565\" y=\"273.312\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1000 -->\n      <g transform=\"translate(373.332565 287.910437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"ma9da927c3a\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#ma9da927c3a\" x=\"44.845313\" y=\"267.187179\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- −0.15 -->\n      <g transform=\"translate(7.2 270.986398) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \nL 4684 2272 \nL 4684 1741 \nL 678 1741 \nL 678 2272 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#ma9da927c3a\" x=\"44.845313\" y=\"233.124861\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- −0.10 -->\n      <g transform=\"translate(7.2 236.92408) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#ma9da927c3a\" x=\"44.845313\" y=\"199.062542\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −0.05 -->\n      <g transform=\"translate(7.2 202.861761) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-2212\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"242.822266\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#ma9da927c3a\" x=\"44.845313\" y=\"165.000224\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.00 -->\n      <g transform=\"translate(15.579688 168.799443) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#ma9da927c3a\" x=\"44.845313\" y=\"130.937905\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.05 -->\n      <g transform=\"translate(15.579688 134.737124) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#ma9da927c3a\" x=\"44.845313\" y=\"96.875587\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.10 -->\n      <g transform=\"translate(15.579688 100.674806) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#ma9da927c3a\" x=\"44.845313\" y=\"62.813269\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.15 -->\n      <g transform=\"translate(15.579688 66.612487) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#ma9da927c3a\" x=\"44.845313\" y=\"28.75095\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.20 -->\n      <g transform=\"translate(15.579688 32.550169) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 61.07804 218.00685 \nL 61.403019 207.632955 \nL 61.727999 225.821449 \nL 62.052978 194.628497 \nL 62.377958 212.755804 \nL 62.702937 195.056503 \nL 63.027917 230.358606 \nL 63.352896 224.800598 \nL 63.677876 189.779572 \nL 64.327835 171.184997 \nL 64.652815 171.637261 \nL 64.977794 234.890321 \nL 65.627753 196.466799 \nL 65.952733 228.181042 \nL 66.277712 173.532499 \nL 66.602692 200.644907 \nL 66.927671 180.921194 \nL 67.252651 232.24048 \nL 67.57763 206.798558 \nL 67.90261 204.184623 \nL 68.227589 208.650563 \nL 68.552569 191.946367 \nL 68.877548 219.838937 \nL 69.202528 172.039463 \nL 69.527507 152.82435 \nL 69.852487 94.606097 \nL 70.177466 200.751686 \nL 70.502446 198.671332 \nL 70.827426 165.624132 \nL 71.152405 211.409535 \nL 71.477385 201.278831 \nL 71.802364 197.077731 \nL 72.127344 199.064741 \nL 72.452323 179.902837 \nL 72.777303 237.365619 \nL 73.102282 211.402374 \nL 73.427262 219.084193 \nL 73.752241 202.20408 \nL 74.077221 231.152909 \nL 74.4022 228.415041 \nL 74.72718 188.796331 \nL 75.052159 200.997111 \nL 75.377139 206.577492 \nL 75.702118 205.367313 \nL 76.352077 158.133183 \nL 76.677057 185.506846 \nL 77.002036 178.905991 \nL 77.327016 179.556226 \nL 77.651996 171.076357 \nL 77.976975 208.503002 \nL 78.301955 166.319784 \nL 78.626934 211.393684 \nL 78.951914 212.33334 \nL 79.276893 247.285854 \nL 79.601873 178.654093 \nL 79.926852 197.206592 \nL 80.251832 206.116864 \nL 80.576811 232.622623 \nL 80.901791 196.888677 \nL 81.55175 231.80455 \nL 82.201709 162.838324 \nL 82.526688 184.921404 \nL 82.851668 193.752289 \nL 83.176647 214.262652 \nL 83.501627 222.750865 \nL 83.826607 153.032332 \nL 84.151586 198.081246 \nL 84.476566 190.9749 \nL 84.801545 245.249831 \nL 85.126525 216.536491 \nL 85.451504 146.637136 \nL 85.776484 192.070455 \nL 86.101463 164.931723 \nL 86.426443 193.110142 \nL 86.751422 181.650483 \nL 87.076402 233.700231 \nL 87.401381 214.832224 \nL 87.726361 217.465909 \nL 88.05134 218.520295 \nL 88.37632 170.57052 \nL 88.701299 219.161471 \nL 89.026279 213.631714 \nL 89.351258 199.400926 \nL 90.001217 189.269684 \nL 90.326197 182.87394 \nL 90.651177 169.582336 \nL 90.976156 199.770973 \nL 91.301136 191.319744 \nL 91.626115 189.830542 \nL 91.951095 211.237526 \nL 92.276074 207.011435 \nL 92.601054 213.287989 \nL 92.926033 230.161796 \nL 93.251013 236.669743 \nL 93.575992 194.879281 \nL 93.900972 231.163949 \nL 94.225951 235.155033 \nL 94.550931 213.252911 \nL 94.87591 233.110696 \nL 95.20089 195.755204 \nL 95.525869 234.993875 \nL 95.850849 234.79337 \nL 96.175828 202.591197 \nL 96.500808 214.861572 \nL 96.825788 208.376146 \nL 97.150767 240.588331 \nL 97.475747 162.441903 \nL 97.800726 222.761362 \nL 98.125706 233.831473 \nL 98.775665 180.451064 \nL 99.100644 198.078485 \nL 99.425624 173.08757 \nL 99.750603 216.591922 \nL 100.075583 219.429487 \nL 100.400562 217.01161 \nL 100.725542 206.47606 \nL 101.050521 180.550809 \nL 101.375501 223.029657 \nL 102.02546 196.739323 \nL 102.350439 141.478386 \nL 102.675419 202.743074 \nL 103.000398 217.998627 \nL 103.325378 166.366156 \nL 103.650358 217.671225 \nL 103.975337 213.371256 \nL 104.300317 211.520992 \nL 104.625296 197.469289 \nL 104.950276 209.774724 \nL 105.275255 154.564142 \nL 105.600235 213.609615 \nL 105.925214 210.886999 \nL 106.250194 212.145139 \nL 106.575173 158.051378 \nL 106.900153 195.977176 \nL 107.225132 191.789498 \nL 107.550112 227.770176 \nL 107.875091 221.56243 \nL 108.200071 181.614242 \nL 108.52505 207.279781 \nL 108.85003 178.923649 \nL 109.175009 203.689237 \nL 109.499989 211.700174 \nL 109.824969 160.140122 \nL 110.149948 227.641416 \nL 110.474928 192.293729 \nL 110.799907 221.257661 \nL 111.124887 226.400864 \nL 111.774846 184.319334 \nL 112.099825 200.361301 \nL 112.424805 237.351711 \nL 112.749784 218.063048 \nL 113.074764 183.017267 \nL 113.399743 228.864934 \nL 113.724723 226.453346 \nL 114.049702 183.364591 \nL 114.374682 241.350861 \nL 114.699661 200.296413 \nL 115.024641 203.8068 \nL 115.34962 172.24418 \nL 115.999579 215.392757 \nL 116.324559 207.987227 \nL 116.649539 233.690323 \nL 116.974518 202.807606 \nL 117.299498 197.600254 \nL 117.624477 219.147178 \nL 117.949457 205.136174 \nL 118.274436 165.51035 \nL 118.599416 217.203638 \nL 118.924395 221.271756 \nL 119.249375 199.643104 \nL 119.574354 195.95046 \nL 119.899334 172.185546 \nL 120.224313 216.892494 \nL 120.549293 165.15854 \nL 120.874272 168.563316 \nL 121.199252 187.711897 \nL 121.524231 137.822353 \nL 121.849211 210.591112 \nL 122.17419 180.551923 \nL 122.49917 173.462546 \nL 122.82415 215.979217 \nL 123.149129 208.370639 \nL 123.474109 212.300627 \nL 123.799088 159.611521 \nL 124.124068 202.775503 \nL 124.449047 208.457935 \nL 125.099006 242.689318 \nL 125.423986 169.568098 \nL 125.748965 240.905652 \nL 126.073945 204.875621 \nL 126.398924 221.61874 \nL 126.723904 212.928402 \nL 127.048883 190.238317 \nL 127.373863 221.908038 \nL 127.698842 171.236332 \nL 128.023822 198.77497 \nL 128.348801 209.521473 \nL 128.673781 231.684373 \nL 128.99876 168.016879 \nL 129.32374 216.265318 \nL 129.64872 175.683243 \nL 129.973699 229.177347 \nL 130.298679 188.966077 \nL 130.623658 228.874339 \nL 130.948638 186.005488 \nL 131.273617 214.317297 \nL 131.598597 192.269277 \nL 131.923576 179.622885 \nL 132.573535 241.61473 \nL 132.898515 168.743924 \nL 133.223494 235.114534 \nL 133.548474 181.830307 \nL 133.873453 162.117054 \nL 134.198433 227.237077 \nL 134.523412 169.740336 \nL 134.848392 223.342096 \nL 135.173371 214.890762 \nL 135.498351 242.058329 \nL 135.823331 197.011539 \nL 136.14831 205.460929 \nL 136.47329 232.18208 \nL 136.798269 149.638285 \nL 137.123249 208.359833 \nL 137.448228 189.726424 \nL 137.773208 230.487665 \nL 138.098187 225.422414 \nL 138.423167 216.24567 \nL 138.748146 201.126931 \nL 139.073126 230.038711 \nL 139.398105 215.126081 \nL 139.723085 218.428314 \nL 140.048064 175.948747 \nL 140.373044 218.340149 \nL 140.698023 231.052385 \nL 141.023003 219.073408 \nL 141.347982 171.585874 \nL 141.672962 193.519684 \nL 141.997941 223.551488 \nL 142.322921 219.270258 \nL 142.647901 222.037707 \nL 142.97288 226.292016 \nL 143.29786 192.246883 \nL 143.622839 218.391723 \nL 143.947819 190.943435 \nL 144.272798 200.684558 \nL 144.597778 201.690276 \nL 144.922757 202.27734 \nL 145.247737 231.453054 \nL 145.572716 153.308038 \nL 145.897696 214.432332 \nL 146.222675 225.700973 \nL 146.547655 229.76202 \nL 146.872634 183.449474 \nL 147.197614 206.259856 \nL 147.522593 199.65033 \nL 147.847573 227.691513 \nL 148.172552 143.401927 \nL 148.822512 201.029311 \nL 149.147491 218.384257 \nL 149.472471 212.482265 \nL 149.79745 175.481079 \nL 150.12243 233.459674 \nL 150.447409 245.284585 \nL 150.772389 234.796791 \nL 151.097368 199.017072 \nL 151.422348 188.025985 \nL 151.747327 206.246789 \nL 152.072307 128.453387 \nL 152.397286 168.581883 \nL 152.722266 164.556132 \nL 153.047245 184.030739 \nL 153.372225 144.165137 \nL 154.022184 240.561359 \nL 154.672143 159.451657 \nL 155.322102 206.697364 \nL 155.647082 191.8609 \nL 155.972061 216.511097 \nL 156.297041 215.558798 \nL 156.62202 185.773991 \nL 156.947 186.376353 \nL 157.596959 220.744834 \nL 157.921938 170.449739 \nL 158.246918 156.981176 \nL 158.571897 213.239476 \nL 158.896877 192.720482 \nL 159.546836 208.351057 \nL 159.871815 236.744503 \nL 160.196795 235.893651 \nL 160.521774 214.833889 \nL 160.846754 210.749088 \nL 161.171733 213.623684 \nL 161.496713 201.481338 \nL 161.821693 198.391454 \nL 162.146672 228.381608 \nL 162.471652 215.897224 \nL 162.796631 231.465556 \nL 163.121611 203.104539 \nL 163.44659 198.65204 \nL 163.77157 189.759431 \nL 164.096549 226.790234 \nL 164.421529 213.931296 \nL 164.746508 214.694836 \nL 165.071488 209.354844 \nL 165.721447 244.385575 \nL 166.046426 201.601109 \nL 166.371406 216.458442 \nL 166.696385 205.80857 \nL 167.021365 214.486398 \nL 167.346344 204.130225 \nL 167.671324 202.599765 \nL 167.996303 222.677669 \nL 168.321283 202.084048 \nL 168.646263 211.707117 \nL 168.971242 204.704982 \nL 169.621201 225.703023 \nL 169.946181 184.760784 \nL 170.27116 172.613669 \nL 170.59614 212.733907 \nL 170.921119 138.178676 \nL 171.246099 203.914191 \nL 171.571078 220.011886 \nL 172.221037 178.668099 \nL 172.546017 238.049729 \nL 172.870996 210.288079 \nL 173.195976 224.993596 \nL 173.520955 133.59359 \nL 174.170914 194.376418 \nL 174.495894 177.248548 \nL 174.820874 231.902034 \nL 175.145853 203.78236 \nL 175.795812 220.447592 \nL 176.120792 237.63229 \nL 176.445771 226.260435 \nL 176.770751 203.445731 \nL 177.09573 217.622651 \nL 177.42071 208.087568 \nL 177.745689 203.476436 \nL 178.070669 223.108599 \nL 178.395648 186.25915 \nL 178.720628 210.696214 \nL 179.370587 188.009882 \nL 179.695566 183.497427 \nL 180.020546 228.889419 \nL 180.345525 180.7603 \nL 180.670505 202.974781 \nL 180.995484 163.212924 \nL 181.320464 191.827634 \nL 181.645444 209.328877 \nL 181.970423 218.670074 \nL 182.295403 169.026559 \nL 182.620382 221.512592 \nL 182.945362 195.489662 \nL 183.270341 188.335322 \nL 183.9203 237.083193 \nL 184.24528 180.51556 \nL 184.570259 206.2725 \nL 184.895239 148.70005 \nL 185.545198 182.754375 \nL 185.870177 189.326268 \nL 186.195157 217.414766 \nL 186.520136 217.066092 \nL 186.845116 174.89569 \nL 187.170095 240.681135 \nL 187.495075 204.783493 \nL 187.820055 205.520913 \nL 188.145034 192.921492 \nL 188.470014 157.64008 \nL 188.794993 179.102473 \nL 189.119973 178.517392 \nL 189.444952 202.219759 \nL 189.769932 216.031369 \nL 190.094911 167.247604 \nL 190.419891 224.260804 \nL 190.74487 215.48451 \nL 191.06985 235.541368 \nL 191.394829 181.777547 \nL 191.719809 209.62886 \nL 192.044788 224.863582 \nL 192.369768 160.62822 \nL 192.694747 184.844594 \nL 193.019727 167.681239 \nL 193.669686 215.060863 \nL 194.319645 181.570292 \nL 194.644625 261.216 \nL 194.969604 214.409836 \nL 195.294584 194.393089 \nL 195.619563 216.107575 \nL 195.944543 188.316758 \nL 196.269522 227.85633 \nL 196.594502 199.917772 \nL 196.919481 162.320422 \nL 197.56944 225.38794 \nL 197.89442 175.147165 \nL 198.219399 199.574367 \nL 198.544379 180.076062 \nL 198.869358 177.134583 \nL 199.194338 184.029272 \nL 199.519317 223.402456 \nL 199.844297 186.417877 \nL 200.169276 168.072985 \nL 200.494256 171.330248 \nL 201.144215 217.221581 \nL 201.469195 179.074095 \nL 201.794174 244.184552 \nL 202.119154 191.12633 \nL 202.444133 178.105378 \nL 202.769113 209.856067 \nL 203.094092 174.730198 \nL 203.419072 199.262261 \nL 203.744051 187.603952 \nL 204.069031 218.928735 \nL 204.71899 175.378981 \nL 205.043969 221.726151 \nL 205.368949 215.646831 \nL 205.693928 153.723198 \nL 206.343887 215.256155 \nL 206.668867 212.351287 \nL 206.993846 214.338259 \nL 207.318826 220.208827 \nL 207.643806 189.000442 \nL 207.968785 246.065442 \nL 208.293765 231.62945 \nL 208.618744 188.895322 \nL 208.943724 201.765084 \nL 209.268703 185.046806 \nL 209.593683 144.462821 \nL 209.918662 215.420541 \nL 210.243642 162.413322 \nL 210.568621 219.410768 \nL 210.893601 209.847946 \nL 211.21858 195.075862 \nL 211.868539 243.764281 \nL 212.193519 180.475011 \nL 212.518498 221.062937 \nL 212.843478 231.007394 \nL 213.168457 142.836811 \nL 213.493437 226.731438 \nL 213.818417 208.00786 \nL 214.143396 216.508864 \nL 214.468376 165.776473 \nL 214.793355 215.076091 \nL 215.118335 220.475184 \nL 215.443314 136.886626 \nL 215.768294 214.639658 \nL 216.093273 203.581523 \nL 216.418253 219.245834 \nL 216.743232 212.492848 \nL 217.068212 177.982892 \nL 217.393191 240.619085 \nL 218.04315 161.170922 \nL 218.36813 206.451973 \nL 218.693109 224.371957 \nL 219.018089 202.158015 \nL 219.343068 209.952617 \nL 219.668048 206.624935 \nL 219.993027 213.156478 \nL 220.318007 183.003974 \nL 220.642987 233.220219 \nL 221.292946 193.096542 \nL 221.617925 214.039266 \nL 221.942905 174.255997 \nL 222.267884 239.328019 \nL 222.917843 173.58018 \nL 223.242823 206.356715 \nL 223.567802 193.183564 \nL 223.892782 203.934986 \nL 224.217761 188.070052 \nL 224.542741 223.38897 \nL 224.86772 188.956469 \nL 225.1927 215.360496 \nL 225.842659 206.073807 \nL 226.167638 163.996757 \nL 226.492618 161.953937 \nL 226.817598 203.907907 \nL 227.142577 187.057291 \nL 227.467557 226.878389 \nL 227.792536 210.305757 \nL 228.117516 220.565115 \nL 228.442495 179.23559 \nL 228.767475 214.609788 \nL 229.092454 221.101371 \nL 229.417434 188.315431 \nL 229.742413 191.128515 \nL 230.067393 183.109371 \nL 230.392372 146.340676 \nL 230.717352 174.287659 \nL 231.042331 153.896649 \nL 231.367311 205.142315 \nL 231.69229 187.864187 \nL 232.342249 223.00605 \nL 232.667229 209.818832 \nL 232.992208 204.433385 \nL 233.317188 217.794823 \nL 233.642168 216.943099 \nL 233.967147 246.308826 \nL 234.292127 178.290377 \nL 234.942086 216.479242 \nL 235.267065 192.440708 \nL 235.592045 182.961562 \nL 235.917024 199.168406 \nL 236.242004 183.871192 \nL 236.566983 175.505046 \nL 236.891963 221.725974 \nL 237.216942 222.745333 \nL 237.541922 199.257634 \nL 237.866901 196.085428 \nL 238.191881 188.688889 \nL 238.51686 195.365947 \nL 238.84184 206.795391 \nL 239.166819 242.844776 \nL 239.491799 202.115532 \nL 239.816779 189.882633 \nL 240.141758 231.681069 \nL 240.791717 168.408031 \nL 241.116697 220.523667 \nL 241.441676 209.873111 \nL 241.766656 125.702094 \nL 242.091635 228.698548 \nL 242.416615 231.712102 \nL 243.391553 198.903915 \nL 243.716533 232.919139 \nL 244.041512 228.273353 \nL 244.366492 231.832264 \nL 244.691471 192.514917 \nL 245.016451 206.402424 \nL 245.34143 210.86894 \nL 245.66641 187.667654 \nL 245.991389 185.516923 \nL 246.316369 159.139117 \nL 246.641349 222.382335 \nL 247.291308 176.98815 \nL 247.616287 221.696677 \nL 247.941267 203.386198 \nL 248.266246 217.446068 \nL 248.591226 208.332378 \nL 248.916205 208.898936 \nL 249.241185 202.896413 \nL 249.566164 210.365178 \nL 249.891144 198.37808 \nL 250.216123 206.925549 \nL 250.541103 188.683778 \nL 250.866082 189.401063 \nL 251.191062 243.669858 \nL 251.516041 203.535505 \nL 251.841021 182.451527 \nL 252.166 205.881736 \nL 252.49098 182.618877 \nL 252.81596 178.799031 \nL 253.140939 215.634258 \nL 253.465919 183.076206 \nL 253.790898 172.961988 \nL 254.115878 187.243343 \nL 254.440857 233.988215 \nL 254.765837 187.167771 \nL 255.090816 205.756521 \nL 255.415796 216.267617 \nL 256.065755 179.24861 \nL 256.390734 184.850228 \nL 256.715714 215.760165 \nL 257.040693 197.948238 \nL 257.365673 167.63533 \nL 257.690652 228.590025 \nL 258.015632 156.042205 \nL 258.665591 200.095578 \nL 258.99057 169.366919 \nL 259.31555 224.387432 \nL 259.64053 178.790869 \nL 259.965509 213.474769 \nL 260.290489 226.540389 \nL 260.940448 187.399821 \nL 261.265427 219.103344 \nL 261.590407 193.443756 \nL 262.240366 203.542722 \nL 262.565345 220.283501 \nL 262.890325 216.134456 \nL 263.215304 194.128958 \nL 263.540284 203.99664 \nL 263.865263 232.93463 \nL 264.190243 220.60371 \nL 264.515222 226.845346 \nL 264.840202 200.009267 \nL 265.165181 198.253431 \nL 265.490161 166.763206 \nL 265.815141 179.871368 \nL 266.14012 178.140791 \nL 266.4651 214.382478 \nL 266.790079 203.450626 \nL 267.115059 205.656647 \nL 267.440038 243.949173 \nL 267.765018 194.532125 \nL 268.089997 216.635573 \nL 268.414977 206.61976 \nL 268.739956 223.384757 \nL 269.064936 173.908344 \nL 269.389915 192.718566 \nL 269.714895 198.55333 \nL 270.039874 177.938099 \nL 270.364854 165.150358 \nL 270.689833 182.329497 \nL 271.014813 213.571958 \nL 271.339792 162.383797 \nL 271.664772 242.4581 \nL 272.314731 177.2665 \nL 272.639711 180.871064 \nL 273.28967 215.061625 \nL 273.614649 190.556496 \nL 273.939629 209.687484 \nL 274.264608 195.306399 \nL 274.589588 214.32254 \nL 274.914567 213.231994 \nL 275.239547 214.19377 \nL 275.564526 222.781705 \nL 275.889506 223.842172 \nL 276.214485 240.525403 \nL 276.539465 172.551254 \nL 276.864444 233.456025 \nL 277.514403 192.341897 \nL 277.839383 185.772717 \nL 278.164362 215.186223 \nL 278.489342 179.222323 \nL 278.814322 239.590229 \nL 279.139301 234.122695 \nL 279.464281 174.604717 \nL 279.78926 234.670996 \nL 280.11424 225.247847 \nL 280.439219 196.699608 \nL 280.764199 227.357685 \nL 281.089178 196.765008 \nL 281.414158 179.05932 \nL 281.739137 196.477349 \nL 282.064117 256.346605 \nL 282.389096 206.464642 \nL 282.714076 135.408542 \nL 283.039055 184.690024 \nL 283.364035 191.695189 \nL 283.689014 231.924732 \nL 284.338973 178.280984 \nL 284.663953 191.643199 \nL 284.988932 227.705248 \nL 285.313912 175.989682 \nL 285.963871 259.798982 \nL 286.288851 235.654805 \nL 286.61383 187.626059 \nL 286.93881 210.169135 \nL 287.263789 205.969649 \nL 287.588769 237.070701 \nL 287.913748 156.981374 \nL 288.238728 190.562632 \nL 288.563707 202.402549 \nL 288.888687 194.899551 \nL 289.213666 218.006789 \nL 289.538646 191.930082 \nL 289.863625 152.473702 \nL 290.188605 160.519367 \nL 290.513584 228.039953 \nL 290.838564 231.833137 \nL 291.163543 211.030504 \nL 291.488523 168.697132 \nL 291.813503 175.004878 \nL 292.138482 175.601763 \nL 292.463462 171.751083 \nL 292.788441 198.092344 \nL 293.113421 176.754978 \nL 293.4384 176.699912 \nL 293.76338 213.998574 \nL 294.088359 196.206412 \nL 294.413339 135.212387 \nL 295.063298 215.164301 \nL 295.388277 193.683186 \nL 295.713257 204.963819 \nL 296.038236 202.660003 \nL 296.363216 233.897152 \nL 296.688195 201.49668 \nL 297.013175 188.299117 \nL 297.663134 200.474803 \nL 297.988113 186.670369 \nL 298.313093 219.54035 \nL 298.638073 187.629706 \nL 298.963052 176.88517 \nL 299.288032 226.578421 \nL 299.937991 192.814093 \nL 300.26297 214.590861 \nL 300.58795 155.29504 \nL 300.912929 182.49884 \nL 301.237909 242.80884 \nL 301.562888 198.245016 \nL 301.887868 234.437194 \nL 302.212847 193.135921 \nL 302.537827 214.161564 \nL 302.862806 197.538773 \nL 303.187786 227.413467 \nL 303.512765 169.567855 \nL 303.837745 204.757622 \nL 304.162724 213.784492 \nL 304.487704 198.281076 \nL 304.812684 230.135123 \nL 305.137663 238.765431 \nL 305.462643 166.378703 \nL 305.787622 166.81279 \nL 306.112602 161.783384 \nL 306.437581 228.543852 \nL 306.762561 220.031158 \nL 307.08754 162.802292 \nL 307.41252 211.844628 \nL 307.737499 203.365685 \nL 308.062479 198.389008 \nL 308.387458 174.639972 \nL 308.712438 220.567074 \nL 309.037417 244.184918 \nL 309.362397 148.62223 \nL 309.687376 228.205121 \nL 310.012356 216.9425 \nL 310.337335 190.037046 \nL 310.662315 213.447315 \nL 310.987294 157.932262 \nL 311.312274 191.898727 \nL 311.637254 189.482439 \nL 311.962233 206.859933 \nL 312.287213 208.477462 \nL 312.612192 192.303657 \nL 312.937172 211.353434 \nL 313.262151 196.553205 \nL 313.587131 215.974603 \nL 313.91211 243.052473 \nL 314.23709 186.446042 \nL 314.562069 206.443507 \nL 314.887049 208.883912 \nL 315.212028 223.371393 \nL 315.537008 185.494529 \nL 315.861987 210.101695 \nL 316.186967 222.725396 \nL 316.511946 168.953007 \nL 316.836926 201.693159 \nL 317.161905 187.244985 \nL 317.486885 212.297551 \nL 317.811865 170.090447 \nL 318.136844 207.426308 \nL 318.461824 200.333085 \nL 318.786803 209.75696 \nL 319.111783 190.39379 \nL 319.436762 203.34726 \nL 319.761742 203.52547 \nL 320.086721 195.195034 \nL 320.411701 226.426364 \nL 320.73668 183.03054 \nL 321.06166 221.453019 \nL 321.386639 231.787501 \nL 321.711619 155.024201 \nL 322.036598 209.766745 \nL 322.361578 223.318778 \nL 323.011537 234.010035 \nL 323.336516 220.569043 \nL 323.661496 218.76272 \nL 323.986475 219.723902 \nL 324.311455 190.849921 \nL 324.636435 210.737505 \nL 324.961414 182.227413 \nL 325.286394 177.195223 \nL 325.936353 211.820259 \nL 326.261332 195.269291 \nL 326.586312 245.487947 \nL 326.911291 166.184695 \nL 327.236271 199.179888 \nL 327.56125 194.437707 \nL 327.88623 205.225904 \nL 328.211209 223.42819 \nL 328.861168 208.923223 \nL 329.186148 208.732378 \nL 329.511127 205.036919 \nL 329.836107 212.257382 \nL 330.161086 203.22968 \nL 330.486066 182.000276 \nL 330.811046 200.917121 \nL 331.136025 181.697636 \nL 331.461005 171.828619 \nL 331.785984 224.552971 \nL 332.110964 223.931311 \nL 332.435943 212.272218 \nL 332.760923 136.933256 \nL 333.085902 196.042546 \nL 333.410882 190.392491 \nL 333.735861 177.356731 \nL 334.060841 183.601757 \nL 334.38582 198.149192 \nL 334.7108 164.699515 \nL 335.035779 209.678114 \nL 335.360759 194.012352 \nL 335.685738 198.445322 \nL 336.010718 196.515267 \nL 336.335697 207.745559 \nL 336.660677 201.190824 \nL 336.985656 134.018354 \nL 337.310636 228.014788 \nL 337.635616 151.581672 \nL 337.960595 196.808035 \nL 338.285575 200.127251 \nL 338.610554 216.015376 \nL 338.935534 139.898368 \nL 339.260513 194.120771 \nL 339.585493 179.178725 \nL 339.910472 220.301991 \nL 340.235452 235.159357 \nL 340.560431 192.627353 \nL 340.885411 188.407884 \nL 341.21039 192.791354 \nL 341.860349 241.723994 \nL 342.185329 205.255668 \nL 342.510308 215.439286 \nL 342.835288 185.471925 \nL 343.160267 191.070982 \nL 343.485247 163.931296 \nL 343.810227 218.668333 \nL 344.135206 199.985335 \nL 344.785165 215.808455 \nL 345.110145 225.002651 \nL 345.435124 221.851993 \nL 345.760104 223.026556 \nL 346.410063 205.90433 \nL 346.735042 212.700337 \nL 347.060022 227.720754 \nL 347.385001 202.688632 \nL 348.35994 222.636739 \nL 348.684919 196.400333 \nL 349.009899 184.395299 \nL 349.334878 128.446809 \nL 349.659858 191.637938 \nL 349.984837 218.973315 \nL 350.309817 213.632993 \nL 350.634797 192.961823 \nL 350.959776 218.661714 \nL 351.284756 208.867117 \nL 351.609735 168.807985 \nL 351.934715 206.577482 \nL 352.584674 229.247793 \nL 352.909653 160.850926 \nL 353.234633 152.85514 \nL 353.559612 172.369757 \nL 353.884592 172.671958 \nL 354.209571 182.535529 \nL 354.534551 169.331511 \nL 354.85953 204.067169 \nL 355.18451 160.116713 \nL 355.509489 193.297557 \nL 355.834469 200.377918 \nL 356.159448 256.455001 \nL 356.484428 164.610259 \nL 356.809408 217.580173 \nL 357.134387 227.177636 \nL 357.459367 214.475201 \nL 357.784346 221.140849 \nL 358.109326 176.866993 \nL 358.434305 175.641313 \nL 358.759285 171.055055 \nL 359.409244 239.509622 \nL 359.734223 201.793993 \nL 360.059203 212.5788 \nL 360.384182 176.391717 \nL 361.034141 218.149943 \nL 361.359121 207.777292 \nL 361.6841 230.172135 \nL 362.00908 183.258819 \nL 362.334059 205.466451 \nL 362.659039 215.72224 \nL 362.984018 216.426409 \nL 363.308998 144.443701 \nL 363.633978 233.344613 \nL 363.958957 198.769059 \nL 364.283937 236.367385 \nL 364.608916 230.102735 \nL 364.933896 174.311743 \nL 365.258875 198.178316 \nL 365.908834 223.023937 \nL 366.233814 177.136086 \nL 366.558793 229.417173 \nL 366.883773 210.496253 \nL 367.533732 231.529007 \nL 367.858711 183.525043 \nL 368.183691 208.015382 \nL 368.50867 198.37272 \nL 368.83365 169.081681 \nL 369.158629 173.290598 \nL 369.483609 204.798428 \nL 369.808589 204.596545 \nL 370.133568 223.761982 \nL 370.458548 218.449276 \nL 370.783527 162.912744 \nL 371.108507 207.293858 \nL 371.433486 184.793801 \nL 371.758466 194.891285 \nL 372.083445 158.924405 \nL 372.408425 228.96258 \nL 372.733404 236.637949 \nL 373.058384 179.798727 \nL 373.383363 171.002186 \nL 373.708343 203.323981 \nL 374.033322 206.746045 \nL 374.358302 218.32545 \nL 374.683281 203.534378 \nL 375.008261 235.148505 \nL 375.33324 204.705368 \nL 375.65822 195.122035 \nL 375.983199 194.634346 \nL 376.308179 225.284701 \nL 376.633159 213.034657 \nL 376.958138 177.043698 \nL 377.283118 206.249578 \nL 377.608097 195.500864 \nL 377.933077 194.610313 \nL 378.258056 197.991655 \nL 378.583036 210.364158 \nL 378.908015 211.180526 \nL 379.232995 212.893857 \nL 379.557974 185.212032 \nL 379.882954 208.701929 \nL 380.207933 171.691256 \nL 380.532913 210.484295 \nL 380.857892 156.187796 \nL 381.182872 223.815357 \nL 381.507851 216.936734 \nL 381.832831 190.634946 \nL 382.15781 208.82814 \nL 382.48279 204.125492 \nL 382.80777 208.712308 \nL 383.132749 205.012896 \nL 383.457729 191.018505 \nL 383.782708 195.329227 \nL 384.107688 218.447627 \nL 384.432667 186.807141 \nL 384.757647 207.173149 \nL 385.082626 188.275127 \nL 385.407606 203.121502 \nL 385.732585 181.444405 \nL 385.732585 181.444405 \n\" clip-path=\"url(#p5afe1c8c66)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 61.07804 71.668907 \nL 61.403019 53.514008 \nL 62.052978 88.133989 \nL 62.377958 93.54797 \nL 62.702937 64.341775 \nL 63.027917 63.800119 \nL 63.352896 100.790438 \nL 63.677876 67.238741 \nL 64.002855 78.427805 \nL 64.327835 64.807926 \nL 64.652815 74.112989 \nL 64.977794 57.710368 \nL 65.302774 69.351249 \nL 65.627753 45.3555 \nL 66.277712 72.12588 \nL 66.602692 53.995731 \nL 66.927671 59.428892 \nL 67.252651 59.33352 \nL 67.57763 100.476112 \nL 67.90261 57.202353 \nL 68.227589 103.644991 \nL 68.552569 72.420696 \nL 68.877548 85.991118 \nL 69.202528 72.225039 \nL 69.527507 68.397955 \nL 69.852487 79.177209 \nL 70.177466 83.102812 \nL 70.502446 22.393313 \nL 70.827426 65.43329 \nL 71.152405 85.956253 \nL 71.477385 54.290942 \nL 71.802364 75.223924 \nL 72.127344 85.630125 \nL 72.452323 83.680201 \nL 72.777303 129.966955 \nL 73.102282 72.909119 \nL 73.427262 69.639385 \nL 73.752241 81.751275 \nL 74.077221 62.300306 \nL 74.4022 57.439763 \nL 74.72718 61.434953 \nL 75.052159 102.641595 \nL 75.377139 83.493792 \nL 75.702118 51.255411 \nL 76.027098 92.978295 \nL 76.352077 75.83334 \nL 76.677057 115.571512 \nL 77.002036 51.282261 \nL 77.327016 72.254417 \nL 77.651996 73.156061 \nL 77.976975 66.27964 \nL 78.301955 69.178575 \nL 78.626934 46.557554 \nL 79.276893 88.138182 \nL 79.601873 59.546231 \nL 79.926852 127.106311 \nL 80.251832 75.590835 \nL 80.576811 69.58334 \nL 81.22677 63.161649 \nL 81.55175 80.383927 \nL 81.876729 74.672999 \nL 82.201709 75.378214 \nL 82.526688 68.594628 \nL 82.851668 98.735118 \nL 83.176647 78.637025 \nL 83.501627 72.959053 \nL 83.826607 78.011295 \nL 84.151586 29.904072 \nL 84.476566 74.579343 \nL 84.801545 74.202727 \nL 85.126525 42.937598 \nL 85.451504 88.859827 \nL 85.776484 45.644043 \nL 86.101463 72.281359 \nL 86.426443 50.011788 \nL 86.751422 60.282743 \nL 87.076402 83.923829 \nL 87.401381 77.782108 \nL 87.726361 107.461238 \nL 88.05134 59.240523 \nL 88.37632 50.101333 \nL 88.701299 95.441452 \nL 89.026279 79.806157 \nL 89.351258 74.910318 \nL 89.676238 89.348732 \nL 90.001217 95.249084 \nL 90.326197 113.282248 \nL 90.651177 67.793634 \nL 90.976156 69.445109 \nL 91.301136 109.349189 \nL 91.626115 114.578282 \nL 91.951095 55.014399 \nL 92.276074 70.870319 \nL 92.601054 74.106533 \nL 92.926033 118.286605 \nL 93.251013 110.223434 \nL 93.575992 47.952503 \nL 93.900972 79.72116 \nL 94.550931 67.43188 \nL 94.87591 135.437159 \nL 95.20089 75.859957 \nL 95.525869 108.427618 \nL 95.850849 79.966467 \nL 96.175828 39.899245 \nL 96.500808 68.435992 \nL 96.825788 77.234015 \nL 97.150767 56.717463 \nL 97.475747 54.4189 \nL 97.800726 127.581872 \nL 98.125706 52.657263 \nL 98.450685 70.704649 \nL 98.775665 63.054867 \nL 99.100644 101.562465 \nL 99.425624 30.433445 \nL 99.750603 104.21128 \nL 100.075583 84.295369 \nL 100.400562 110.794078 \nL 100.725542 70.141847 \nL 101.050521 85.592971 \nL 101.375501 83.874458 \nL 101.70048 56.45303 \nL 102.02546 89.970005 \nL 102.350439 102.152574 \nL 102.675419 82.524433 \nL 103.325378 58.501768 \nL 103.650358 79.130584 \nL 103.975337 78.689924 \nL 104.300317 93.075571 \nL 104.625296 76.924612 \nL 104.950276 84.106325 \nL 105.275255 80.40024 \nL 105.600235 83.832512 \nL 105.925214 72.433822 \nL 106.250194 74.337476 \nL 106.575173 94.238937 \nL 106.900153 144.625537 \nL 107.225132 74.233242 \nL 107.550112 50.58465 \nL 107.875091 130.093669 \nL 108.200071 70.012306 \nL 108.52505 73.203945 \nL 108.85003 95.817946 \nL 109.175009 70.050607 \nL 109.824969 102.252859 \nL 110.149948 89.165195 \nL 110.474928 65.903948 \nL 110.799907 76.087581 \nL 111.124887 99.946825 \nL 111.449866 78.638883 \nL 112.099825 69.861294 \nL 112.424805 74.57851 \nL 112.749784 66.062391 \nL 113.074764 67.466466 \nL 113.399743 110.505845 \nL 113.724723 91.493045 \nL 114.049702 90.61582 \nL 114.374682 47.543748 \nL 114.699661 49.621021 \nL 115.024641 68.418948 \nL 115.34962 80.587589 \nL 115.6746 63.116942 \nL 115.999579 61.782455 \nL 116.649539 104.532413 \nL 116.974518 101.450982 \nL 117.299498 93.281669 \nL 117.624477 77.328859 \nL 118.274436 75.753733 \nL 118.599416 82.342018 \nL 118.924395 81.968783 \nL 119.249375 61.955038 \nL 119.574354 126.552616 \nL 119.899334 82.763797 \nL 120.224313 62.070662 \nL 120.549293 104.781594 \nL 120.874272 33.670846 \nL 121.199252 84.349333 \nL 121.524231 62.250493 \nL 122.17419 82.151015 \nL 122.49917 122.019692 \nL 122.82415 78.922197 \nL 123.149129 83.942137 \nL 123.474109 59.19804 \nL 123.799088 65.156097 \nL 124.124068 67.763546 \nL 124.449047 72.62216 \nL 124.774027 96.628608 \nL 125.099006 77.323256 \nL 125.423986 50.142994 \nL 125.748965 83.956176 \nL 126.073945 43.381639 \nL 126.723904 96.109407 \nL 127.048883 68.67596 \nL 127.373863 83.029347 \nL 127.698842 76.505696 \nL 128.023822 66.945417 \nL 128.348801 77.7078 \nL 128.673781 79.439155 \nL 128.99876 43.552091 \nL 129.32374 56.855755 \nL 129.64872 95.396578 \nL 129.973699 55.536616 \nL 130.298679 45.19051 \nL 130.623658 94.626714 \nL 130.948638 57.942113 \nL 131.273617 57.666615 \nL 131.598597 68.140303 \nL 131.923576 52.256132 \nL 132.248556 106.611945 \nL 132.573535 63.533098 \nL 132.898515 108.143846 \nL 133.223494 58.414436 \nL 133.548474 97.181431 \nL 133.873453 66.110193 \nL 134.198433 77.862293 \nL 134.523412 72.428574 \nL 134.848392 103.35014 \nL 135.173371 61.832359 \nL 135.498351 117.614296 \nL 135.823331 97.573375 \nL 136.14831 92.323472 \nL 136.47329 80.265806 \nL 136.798269 87.574852 \nL 137.123249 71.159775 \nL 137.773208 92.48131 \nL 138.098187 42.538792 \nL 138.423167 60.202903 \nL 138.748146 68.294279 \nL 139.073126 41.328719 \nL 139.398105 66.714382 \nL 139.723085 81.69934 \nL 140.048064 59.33688 \nL 140.373044 52.995436 \nL 140.698023 76.632821 \nL 141.023003 79.412812 \nL 141.347982 19.296 \nL 141.672962 91.899972 \nL 141.997941 111.485908 \nL 142.322921 94.601244 \nL 142.647901 65.023155 \nL 142.97288 74.137647 \nL 143.29786 90.81668 \nL 143.622839 124.765859 \nL 144.272798 76.370571 \nL 144.597778 82.000034 \nL 144.922757 80.31469 \nL 145.247737 66.575633 \nL 145.572716 61.590726 \nL 145.897696 48.839681 \nL 146.222675 89.12329 \nL 146.547655 46.308937 \nL 146.872634 49.326013 \nL 147.197614 108.41237 \nL 147.522593 52.022834 \nL 147.847573 94.401745 \nL 148.172552 99.079492 \nL 148.497532 42.772994 \nL 148.822512 48.060808 \nL 149.147491 95.26925 \nL 149.472471 100.168784 \nL 150.12243 62.986599 \nL 150.447409 87.079588 \nL 150.772389 81.37167 \nL 151.097368 46.19447 \nL 151.422348 92.451699 \nL 151.747327 71.778501 \nL 152.072307 85.986535 \nL 152.397286 72.905627 \nL 152.722266 74.678115 \nL 153.047245 63.685338 \nL 153.372225 90.202522 \nL 153.697204 78.790696 \nL 154.022184 50.843641 \nL 154.347163 108.905072 \nL 154.672143 70.678357 \nL 154.997122 58.425074 \nL 155.322102 87.487601 \nL 155.647082 56.040804 \nL 155.972061 87.141054 \nL 156.297041 39.223438 \nL 156.62202 91.051339 \nL 156.947 65.453563 \nL 157.271979 68.061671 \nL 157.596959 110.356671 \nL 157.921938 56.766606 \nL 158.246918 49.028842 \nL 158.571897 62.670882 \nL 158.896877 61.011804 \nL 159.221856 81.431492 \nL 159.546836 78.72255 \nL 159.871815 98.586238 \nL 160.196795 60.124626 \nL 160.521774 66.776042 \nL 160.846754 78.073756 \nL 161.171733 125.664777 \nL 161.496713 81.959606 \nL 161.821693 113.639931 \nL 162.146672 99.448058 \nL 162.471652 64.043305 \nL 162.796631 62.497161 \nL 163.121611 104.774538 \nL 163.44659 73.514597 \nL 163.77157 78.438586 \nL 164.421529 52.643752 \nL 165.721447 92.23316 \nL 166.046426 51.341393 \nL 167.021365 85.79846 \nL 167.346344 63.674151 \nL 167.671324 122.396343 \nL 167.996303 76.752029 \nL 168.321283 75.98354 \nL 168.646263 95.07212 \nL 168.971242 51.50417 \nL 169.296222 56.097022 \nL 169.621201 109.99447 \nL 169.946181 59.933242 \nL 170.27116 56.130724 \nL 170.59614 99.413442 \nL 170.921119 107.923851 \nL 171.246099 42.465326 \nL 171.571078 92.370478 \nL 171.896058 113.005146 \nL 172.221037 62.739089 \nL 172.546017 85.617182 \nL 172.870996 62.870894 \nL 173.195976 68.01134 \nL 173.520955 85.350039 \nL 173.845935 48.503032 \nL 174.170914 68.120285 \nL 174.495894 114.492813 \nL 174.820874 88.592496 \nL 175.145853 103.702326 \nL 175.470833 96.214951 \nL 175.795812 72.931553 \nL 176.120792 111.020438 \nL 176.770751 54.137271 \nL 177.09573 43.982488 \nL 177.42071 77.464949 \nL 177.745689 62.378908 \nL 178.070669 82.541086 \nL 178.395648 79.081634 \nL 178.720628 99.937612 \nL 179.045607 42.940268 \nL 179.695566 104.048122 \nL 180.020546 117.496205 \nL 180.345525 78.933658 \nL 180.670505 62.425787 \nL 180.995484 35.709473 \nL 181.320464 59.516681 \nL 181.645444 48.090846 \nL 181.970423 65.785147 \nL 182.295403 107.251445 \nL 182.620382 66.922587 \nL 182.945362 95.253002 \nL 183.595321 56.046671 \nL 183.9203 100.663633 \nL 184.24528 66.133663 \nL 184.570259 86.383103 \nL 184.895239 74.569993 \nL 185.220218 94.8813 \nL 185.545198 54.84408 \nL 185.870177 71.225048 \nL 186.195157 106.548819 \nL 186.520136 82.30663 \nL 186.845116 120.057972 \nL 187.170095 107.188233 \nL 187.495075 55.790897 \nL 187.820055 69.391367 \nL 188.145034 45.856257 \nL 188.470014 82.505277 \nL 188.794993 30.19567 \nL 189.119973 56.625461 \nL 189.444952 72.572723 \nL 189.769932 52.070291 \nL 190.094911 140.833455 \nL 190.419891 54.32703 \nL 190.74487 69.921289 \nL 191.06985 124.430895 \nL 191.394829 55.733644 \nL 192.044788 72.451729 \nL 192.369768 77.021101 \nL 192.694747 89.30331 \nL 193.019727 82.374898 \nL 193.344706 56.705911 \nL 193.994665 116.13378 \nL 194.319645 54.084992 \nL 194.644625 82.021205 \nL 194.969604 70.812071 \nL 195.294584 78.147557 \nL 195.619563 92.25123 \nL 195.944543 77.836204 \nL 196.269522 77.698267 \nL 196.594502 80.880755 \nL 196.919481 46.263936 \nL 197.244461 94.33837 \nL 197.56944 82.64328 \nL 197.89442 79.451428 \nL 198.219399 68.766521 \nL 198.544379 79.212587 \nL 198.869358 59.650587 \nL 199.194338 86.005492 \nL 199.519317 68.097627 \nL 199.844297 83.871671 \nL 200.169276 46.007502 \nL 200.494256 110.515134 \nL 200.819236 40.847331 \nL 201.144215 35.70458 \nL 201.469195 95.2646 \nL 201.794174 107.747299 \nL 202.119154 80.759411 \nL 202.444133 124.173344 \nL 202.769113 100.380293 \nL 203.094092 55.816154 \nL 203.419072 47.569563 \nL 203.744051 67.185811 \nL 204.069031 64.355744 \nL 204.39401 121.972834 \nL 204.71899 89.700857 \nL 205.043969 88.86978 \nL 205.368949 92.913697 \nL 205.693928 78.446088 \nL 206.018908 69.980755 \nL 206.343887 69.569767 \nL 206.668867 87.342031 \nL 206.993846 69.082472 \nL 207.318826 63.810808 \nL 207.643806 82.486563 \nL 207.968785 55.689932 \nL 208.293765 90.663551 \nL 208.943724 45.769097 \nL 209.593683 65.954441 \nL 209.918662 95.963999 \nL 210.243642 55.463008 \nL 210.568621 61.592624 \nL 210.893601 64.460364 \nL 211.21858 84.978713 \nL 211.54356 66.620167 \nL 211.868539 80.479218 \nL 212.193519 56.417947 \nL 212.518498 121.690372 \nL 213.168457 71.031381 \nL 213.493437 106.366297 \nL 213.818417 117.308577 \nL 214.143396 89.444977 \nL 214.468376 84.975596 \nL 214.793355 98.332707 \nL 215.118335 54.744322 \nL 215.768294 79.602704 \nL 216.093273 89.284316 \nL 216.418253 62.201452 \nL 217.068212 91.025331 \nL 217.393191 93.151483 \nL 217.718171 52.971438 \nL 218.04315 63.891573 \nL 218.36813 43.217684 \nL 219.018089 111.427777 \nL 219.343068 92.335729 \nL 219.993027 112.484244 \nL 220.318007 102.292601 \nL 220.642987 56.761347 \nL 220.967966 92.856327 \nL 221.292946 49.255593 \nL 221.617925 82.005003 \nL 221.942905 28.585999 \nL 222.267884 95.705286 \nL 222.592864 89.990481 \nL 222.917843 76.145617 \nL 223.242823 85.219792 \nL 223.567802 79.002575 \nL 223.892782 87.659109 \nL 224.217761 100.087685 \nL 224.542741 69.121219 \nL 224.86772 91.07357 \nL 225.1927 93.060664 \nL 225.517679 33.225618 \nL 225.842659 124.9017 \nL 226.167638 56.478926 \nL 226.492618 106.31988 \nL 226.817598 26.590748 \nL 227.142577 112.105933 \nL 227.467557 56.428982 \nL 227.792536 62.51652 \nL 228.117516 42.552222 \nL 228.442495 40.668322 \nL 228.767475 66.259865 \nL 229.417434 80.71038 \nL 229.742413 42.069799 \nL 230.067393 115.290679 \nL 230.392372 73.357484 \nL 230.717352 72.47996 \nL 231.042331 61.290388 \nL 231.367311 82.633179 \nL 231.69229 64.72302 \nL 232.01727 40.099765 \nL 232.342249 52.876949 \nL 232.667229 99.117722 \nL 232.992208 85.937072 \nL 233.317188 66.793207 \nL 233.642168 78.711475 \nL 233.967147 110.318431 \nL 234.292127 62.67884 \nL 234.617106 84.678009 \nL 234.942086 79.144299 \nL 235.267065 77.065797 \nL 235.592045 64.781908 \nL 235.917024 62.933467 \nL 236.242004 55.354825 \nL 236.566983 94.046 \nL 236.891963 72.94208 \nL 237.216942 90.372669 \nL 237.541922 92.646189 \nL 237.866901 31.001698 \nL 238.191881 83.593539 \nL 238.51686 70.347544 \nL 238.84184 34.350988 \nL 239.166819 94.808825 \nL 239.816779 66.94295 \nL 240.141758 117.481983 \nL 240.466738 68.471146 \nL 240.791717 60.83448 \nL 241.116697 49.587096 \nL 241.441676 85.572836 \nL 241.766656 65.383965 \nL 242.091635 113.849328 \nL 242.416615 78.537876 \nL 242.741594 78.087136 \nL 243.066574 35.801577 \nL 243.391553 67.526237 \nL 243.716533 82.946953 \nL 244.041512 65.787532 \nL 244.366492 77.118422 \nL 244.691471 148.847428 \nL 245.016451 53.9199 \nL 245.34143 84.183079 \nL 245.66641 60.928847 \nL 245.991389 51.932202 \nL 246.316369 90.613348 \nL 246.641349 73.781436 \nL 246.966328 46.825499 \nL 247.291308 46.663625 \nL 247.616287 68.534917 \nL 247.941267 79.043546 \nL 248.591226 50.811319 \nL 248.916205 71.279571 \nL 249.241185 60.058083 \nL 249.566164 57.982607 \nL 249.891144 87.828175 \nL 250.216123 65.389954 \nL 250.541103 51.608272 \nL 251.191062 75.60595 \nL 251.516041 78.750578 \nL 251.841021 88.991439 \nL 252.166 118.013102 \nL 252.49098 47.447249 \nL 252.81596 68.305486 \nL 253.140939 71.314482 \nL 253.465919 59.875125 \nL 253.790898 85.887148 \nL 254.115878 63.047517 \nL 254.440857 66.147398 \nL 254.765837 53.193001 \nL 255.090816 60.135315 \nL 255.415796 87.440464 \nL 255.740775 58.296091 \nL 256.065755 101.651969 \nL 256.390734 64.705773 \nL 256.715714 57.079958 \nL 257.040693 95.532023 \nL 257.365673 43.69694 \nL 257.690652 111.672201 \nL 258.015632 87.178071 \nL 258.340611 111.457058 \nL 258.665591 59.40733 \nL 258.99057 71.284129 \nL 259.31555 51.557668 \nL 259.64053 78.836022 \nL 259.965509 53.903333 \nL 260.290489 57.556097 \nL 260.615468 98.812948 \nL 260.940448 82.241987 \nL 261.265427 46.568243 \nL 261.590407 76.788178 \nL 261.915386 140.275973 \nL 262.240366 54.656848 \nL 262.565345 63.353652 \nL 262.890325 58.112382 \nL 263.215304 46.057193 \nL 263.540284 92.345947 \nL 263.865263 88.60017 \nL 264.515222 58.685315 \nL 264.840202 89.393961 \nL 265.165181 86.537627 \nL 265.490161 66.056726 \nL 265.815141 74.598955 \nL 266.14012 86.863105 \nL 266.4651 40.298051 \nL 266.790079 70.028954 \nL 267.115059 76.853096 \nL 267.440038 67.107829 \nL 267.765018 33.607938 \nL 268.089997 40.452941 \nL 268.414977 53.08222 \nL 268.739956 89.701461 \nL 269.064936 83.557258 \nL 269.389915 92.6513 \nL 269.714895 76.907679 \nL 270.039874 125.047641 \nL 270.364854 65.546184 \nL 270.689833 98.191705 \nL 271.014813 58.624143 \nL 271.339792 74.025698 \nL 271.664772 110.231383 \nL 271.989751 68.297741 \nL 272.314731 81.780612 \nL 272.639711 71.599187 \nL 272.96469 73.056679 \nL 273.28967 83.424681 \nL 273.614649 36.653093 \nL 273.939629 88.364623 \nL 274.264608 61.866264 \nL 274.589588 61.598096 \nL 274.914567 84.20221 \nL 275.239547 93.374874 \nL 275.564526 71.460235 \nL 275.889506 65.098042 \nL 276.214485 82.86458 \nL 276.539465 59.609566 \nL 276.864444 73.233181 \nL 277.189424 94.491234 \nL 277.514403 55.759053 \nL 277.839383 84.239328 \nL 278.164362 55.740435 \nL 278.489342 81.698879 \nL 278.814322 79.393088 \nL 279.139301 62.897907 \nL 279.464281 69.901737 \nL 279.78926 51.028041 \nL 280.439219 90.989192 \nL 280.764199 85.823433 \nL 281.089178 62.292652 \nL 281.414158 57.322352 \nL 282.064117 96.947747 \nL 282.389096 61.613028 \nL 283.039055 136.823373 \nL 283.689014 55.222888 \nL 284.338973 96.669173 \nL 284.663953 70.288098 \nL 284.988932 78.958285 \nL 285.313912 60.004383 \nL 285.638892 86.670645 \nL 285.963871 99.136127 \nL 286.288851 78.228554 \nL 286.61383 78.549124 \nL 286.93881 56.305419 \nL 287.263789 103.029834 \nL 287.588769 79.581061 \nL 287.913748 84.502045 \nL 288.238728 64.175598 \nL 288.563707 146.237675 \nL 288.888687 63.469225 \nL 289.538646 93.401785 \nL 289.863625 35.441934 \nL 290.188605 43.346515 \nL 290.513584 75.254154 \nL 290.838564 64.465642 \nL 291.163543 69.447251 \nL 291.488523 65.692242 \nL 291.813503 88.905767 \nL 292.138482 86.150159 \nL 292.463462 95.26622 \nL 292.788441 52.208106 \nL 293.4384 106.126548 \nL 293.76338 99.97835 \nL 294.413339 67.111006 \nL 294.738318 109.9824 \nL 295.063298 72.033188 \nL 295.388277 64.49029 \nL 295.713257 88.313501 \nL 296.038236 70.605267 \nL 296.363216 119.77344 \nL 296.688195 73.920479 \nL 297.013175 81.238271 \nL 297.663134 48.909086 \nL 297.988113 58.312039 \nL 298.313093 82.380294 \nL 298.638073 124.120593 \nL 298.963052 84.177161 \nL 299.613011 62.918301 \nL 299.937991 46.133907 \nL 300.26297 73.727136 \nL 300.58795 83.539534 \nL 300.912929 55.960141 \nL 301.237909 65.798303 \nL 301.562888 65.247561 \nL 301.887868 75.453223 \nL 302.212847 52.942141 \nL 302.537827 62.164176 \nL 303.187786 99.4737 \nL 303.837745 48.506524 \nL 304.162724 55.373555 \nL 304.487704 107.788442 \nL 304.812684 61.876883 \nL 305.137663 89.00657 \nL 305.462643 63.779979 \nL 305.787622 67.316185 \nL 306.112602 62.095817 \nL 306.437581 50.034933 \nL 307.08754 93.287744 \nL 307.41252 41.81165 \nL 307.737499 78.133629 \nL 308.062479 63.6305 \nL 308.387458 76.508203 \nL 309.037417 67.086937 \nL 309.362397 108.875029 \nL 309.687376 80.220779 \nL 310.012356 93.831106 \nL 310.337335 96.19208 \nL 310.662315 64.30049 \nL 311.312274 89.797102 \nL 311.637254 98.95122 \nL 311.962233 94.648276 \nL 312.287213 98.493647 \nL 312.612192 34.793922 \nL 312.937172 112.697478 \nL 313.262151 100.806112 \nL 313.587131 55.984382 \nL 313.91211 95.568821 \nL 314.23709 38.688766 \nL 314.562069 71.821136 \nL 314.887049 52.520047 \nL 315.212028 65.350821 \nL 315.537008 64.443391 \nL 316.186967 109.297087 \nL 316.511946 64.228141 \nL 317.161905 75.204443 \nL 317.486885 103.270914 \nL 317.811865 75.047006 \nL 318.136844 64.523028 \nL 318.461824 78.354056 \nL 318.786803 79.095998 \nL 319.111783 67.149053 \nL 319.436762 70.767253 \nL 319.761742 93.83171 \nL 320.086721 57.816744 \nL 320.411701 49.85636 \nL 320.73668 63.07584 \nL 321.06166 53.206909 \nL 321.386639 82.530042 \nL 321.711619 42.306072 \nL 322.036598 77.304953 \nL 322.361578 84.561766 \nL 322.686557 69.918913 \nL 323.011537 74.03458 \nL 323.336516 54.905151 \nL 323.661496 83.592169 \nL 323.986475 40.099623 \nL 324.311455 78.048124 \nL 324.636435 67.404908 \nL 324.961414 79.713181 \nL 325.286394 85.821012 \nL 325.611373 48.364689 \nL 326.261332 122.964464 \nL 326.586312 100.615789 \nL 326.911291 64.482148 \nL 327.236271 90.341302 \nL 327.56125 46.431088 \nL 328.211209 107.804258 \nL 328.536189 79.182579 \nL 328.861168 61.902545 \nL 329.186148 97.162113 \nL 329.511127 57.648566 \nL 329.836107 93.189246 \nL 330.161086 76.046428 \nL 330.486066 47.168635 \nL 330.811046 46.343106 \nL 331.461005 84.044777 \nL 331.785984 86.118558 \nL 332.110964 137.953514 \nL 332.435943 64.774102 \nL 332.760923 70.019503 \nL 333.085902 53.316726 \nL 333.410882 83.888208 \nL 334.38582 63.977179 \nL 334.7108 112.780166 \nL 335.035779 52.061429 \nL 335.360759 104.657701 \nL 335.685738 52.934162 \nL 336.010718 58.437591 \nL 336.335697 86.185902 \nL 336.660677 70.625956 \nL 336.985656 63.700595 \nL 337.310636 92.948643 \nL 337.635616 65.902019 \nL 338.285575 103.641733 \nL 338.610554 100.938887 \nL 338.935534 51.899647 \nL 339.260513 49.252365 \nL 339.585493 74.786603 \nL 339.910472 111.285947 \nL 340.235452 60.695102 \nL 340.560431 94.47554 \nL 340.885411 49.544399 \nL 341.21039 103.158959 \nL 341.53537 95.01275 \nL 341.860349 100.617546 \nL 342.185329 51.084513 \nL 342.510308 105.13013 \nL 342.835288 56.356663 \nL 343.160267 118.908554 \nL 343.485247 81.373538 \nL 343.810227 66.79139 \nL 344.135206 62.563064 \nL 344.460186 77.955828 \nL 344.785165 60.19671 \nL 345.110145 62.032229 \nL 345.435124 78.805375 \nL 345.760104 73.923433 \nL 346.085083 93.248992 \nL 346.410063 73.686794 \nL 346.735042 111.310173 \nL 347.060022 66.595621 \nL 347.385001 83.51449 \nL 347.709981 73.592011 \nL 348.03496 22.150624 \nL 348.35994 80.299432 \nL 348.684919 37.507777 \nL 349.009899 85.414033 \nL 349.334878 61.973919 \nL 349.659858 84.505832 \nL 349.984837 72.143858 \nL 350.309817 112.776106 \nL 350.634797 84.068196 \nL 350.959776 33.220349 \nL 351.284756 69.484273 \nL 351.609735 65.887604 \nL 351.934715 93.124358 \nL 352.584674 57.088749 \nL 353.234633 85.50235 \nL 353.559612 98.084238 \nL 353.884592 87.663662 \nL 354.209571 132.201539 \nL 354.534551 68.22189 \nL 354.85953 80.576838 \nL 355.18451 47.918455 \nL 355.509489 76.017141 \nL 355.834469 56.695902 \nL 356.159448 95.362926 \nL 356.809408 37.563021 \nL 357.459367 69.601419 \nL 357.784346 97.406594 \nL 358.109326 50.1152 \nL 358.434305 79.677682 \nL 358.759285 55.872169 \nL 359.084264 82.3542 \nL 359.409244 39.625909 \nL 359.734223 102.869331 \nL 360.059203 87.179883 \nL 360.384182 58.129243 \nL 360.709162 68.901392 \nL 361.034141 108.075538 \nL 361.359121 107.990129 \nL 361.6841 80.077178 \nL 362.00908 98.61923 \nL 362.334059 38.459822 \nL 362.659039 56.487514 \nL 362.984018 57.144277 \nL 363.308998 60.09942 \nL 363.633978 76.849827 \nL 363.958957 52.646554 \nL 364.608916 94.363109 \nL 364.933896 100.381384 \nL 365.258875 90.48068 \nL 365.583855 66.820149 \nL 365.908834 124.646012 \nL 366.233814 74.410109 \nL 366.558793 76.030399 \nL 366.883773 54.029849 \nL 367.208752 76.895955 \nL 367.533732 72.793769 \nL 367.858711 46.275336 \nL 368.183691 87.852812 \nL 368.83365 58.461335 \nL 369.158629 107.506874 \nL 369.483609 62.561968 \nL 369.808589 68.835986 \nL 370.133568 63.94374 \nL 370.458548 64.089819 \nL 370.783527 48.374312 \nL 371.108507 83.456282 \nL 371.433486 68.62563 \nL 371.758466 90.667008 \nL 372.083445 86.202013 \nL 372.408425 73.685698 \nL 372.733404 84.527728 \nL 373.058384 27.813663 \nL 373.383363 60.545501 \nL 373.708343 63.517799 \nL 374.033322 100.190346 \nL 374.358302 118.222728 \nL 374.683281 113.214457 \nL 375.008261 102.622272 \nL 375.33324 59.851016 \nL 375.65822 53.3029 \nL 375.983199 32.719999 \nL 376.308179 65.169761 \nL 376.633159 57.054752 \nL 376.958138 70.655669 \nL 377.283118 52.352225 \nL 377.608097 143.809733 \nL 377.933077 47.707145 \nL 378.583036 81.741834 \nL 378.908015 79.459955 \nL 379.232995 107.730437 \nL 379.557974 78.942215 \nL 379.882954 74.668401 \nL 380.207933 134.16534 \nL 380.532913 77.8339 \nL 380.857892 51.379603 \nL 381.182872 89.664652 \nL 381.507851 87.264576 \nL 381.832831 115.091997 \nL 382.15781 51.925746 \nL 382.48279 55.961014 \nL 383.132749 66.217108 \nL 383.457729 87.570244 \nL 383.782708 75.12975 \nL 384.107688 49.038506 \nL 384.432667 87.610078 \nL 384.757647 93.584144 \nL 385.082626 120.796575 \nL 385.407606 54.090463 \nL 385.732585 83.610279 \nL 385.732585 83.610279 \n\" clip-path=\"url(#p5afe1c8c66)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 44.845313 273.312 \nL 44.845313 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 401.965312 273.312 \nL 401.965312 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 44.845313 273.312 \nL 401.965312 273.312 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 44.845313 7.2 \nL 401.965312 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p5afe1c8c66\">\n   <rect x=\"44.845313\" y=\"7.2\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NKmhNDR15nJo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To Do\n",
        "\n",
        "```python\n",
        "# use GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# import dataset (comes with colab!)\n",
        "data = np.loadtxt(open('sample_data/mnist_train_small.csv','rb'),delimiter=',')\n",
        "\n",
        "# extract labels (number IDs) and remove from data\n",
        "labels = data[:,0]\n",
        "data   = data[:,1:]\n",
        "\n",
        "# normalize the data to a range of [0 1]\n",
        "dataNorm = data / np.max(data)\n",
        "\n",
        "# Create train/test groups using DataLoader\n",
        "# Step 1: convert to tensor\n",
        "dataT   = torch.tensor( dataNorm ).float()\n",
        "labelsT = torch.tensor( labels ).long()\n",
        "\n",
        "# Step 2: use scikitlearn to split the data\n",
        "train_data,test_data, train_labels,test_labels = train_test_split(dataT, labelsT, test_size=.1)\n",
        "\n",
        "\n",
        "# Step 3: convert into PyTorch Datasets\n",
        "train_data = torch.utils.data.TensorDataset(train_data,train_labels)\n",
        "test_data  = torch.utils.data.TensorDataset(test_data,test_labels)\n",
        "\n",
        "# Step 4: translate into dataloader objects\n",
        "batchsize    = 32\n",
        "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
        "test_loader  = DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])\n",
        "\n",
        "\n",
        "# create a class for the model\n",
        "def createTheMNISTNet(nUnits,nLayers):\n",
        "\n",
        "  class mnistNet(nn.Module):\n",
        "    def __init__(self,nUnits,nLayers):\n",
        "      super().__init__()\n",
        "\n",
        "      # create dictionary to store the layers\n",
        "      self.layers = nn.ModuleDict()\n",
        "      self.nLayers = nLayers\n",
        "\n",
        "      ### input layer\n",
        "      self.layers['input'] = nn.Linear(784,nUnits)\n",
        "\n",
        "      ### hidden layers\n",
        "      for i in range(nLayers):\n",
        "        self.layers[f'hidden{i}'] = nn.Linear(nUnits,nUnits)\n",
        "\n",
        "      ### output layer\n",
        "      self.layers['output'] = nn.Linear(nUnits,10)\n",
        "\n",
        "\n",
        "\n",
        "    # forward pass\n",
        "    def forward(self,x):\n",
        "      # input layer\n",
        "      x = self.layers['input'](x)\n",
        "\n",
        "      # hidden layers\n",
        "      for i in range(self.nLayers):\n",
        "        x = F.relu( self.layers[f'hidden{i}'](x) )\n",
        "\n",
        "      # return output layer\n",
        "      x = self.layers['output'](x)\n",
        "      return F.log_softmax(x,dim=1)\n",
        "\n",
        "  # create the model instance\n",
        "  net = mnistNet(nUnits,nLayers)\n",
        "\n",
        "  # loss function\n",
        "  lossfun = nn.NLLLoss()\n",
        "\n",
        "  # optimizer\n",
        "  optimizer = torch.optim.SGD(net.parameters(),lr=.01)\n",
        "\n",
        "  return net,lossfun,optimizer\n",
        "\n",
        "# Generate an instance of the model and confirm that it returns the expected network.\n",
        "nUnitsPerLayer = 12\n",
        "nLayers = 4\n",
        "net = createTheMNISTNet(nUnitsPerLayer,nLayers)\n",
        "\n",
        "\n",
        "# a function that trains the model\n",
        "\n",
        "def function2trainTheModel(nUnits,nLayers):\n",
        "\n",
        "  # number of epochs\n",
        "  numepochs = 60\n",
        "\n",
        "  # create a new model\n",
        "  net,lossfun,optimizer = createTheMNISTNet(nUnits,nLayers)\n",
        "\n",
        "  # New!\n",
        "  net.to(device)\n",
        "\n",
        "  # initialize losses\n",
        "  losses    = torch.zeros(numepochs)\n",
        "  trainAcc  = []\n",
        "  testAcc   = []\n",
        "\n",
        "\n",
        "  # loop over epochs\n",
        "  for epochi in range(numepochs):\n",
        "\n",
        "    # loop over training data batches\n",
        "    batchAcc  = []\n",
        "    batchLoss = []\n",
        "    for X,y in train_loader:\n",
        "\n",
        "      # New!\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      # forward pass and loss\n",
        "      yHat = net(X)\n",
        "      loss = lossfun(yHat,y)\n",
        "\n",
        "      # backprop\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # loss from this batch\n",
        "      batchLoss.append(loss.item())\n",
        "\n",
        "      # New! bring outputs back\n",
        "      yHat = yHat.cpu()\n",
        "      y = y.cpu()\n",
        "\n",
        "      # compute accuracy\n",
        "      matches = torch.argmax(yHat,axis=1) == y     # booleans (false/true)\n",
        "      matchesNumeric = matches.float()             # convert to numbers (0/1)\n",
        "      accuracyPct = 100*torch.mean(matchesNumeric) # average and x100\n",
        "      batchAcc.append( accuracyPct )               # add to list of accuracies\n",
        "    # end of batch loop...\n",
        "\n",
        "    # now that we've trained through the batches, get their average training accuracy\n",
        "    trainAcc.append( np.mean(batchAcc) )\n",
        "\n",
        "    # and get average losses across the batches\n",
        "    losses[epochi] = np.mean(batchLoss)\n",
        "\n",
        "    # test accuracy\n",
        "    X,y = next(iter(test_loader)) # extract X,y from test dataloader\n",
        "\n",
        "    # New!\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    with torch.no_grad(): # deactivates autograd\n",
        "      yHat = net(X)\n",
        "\n",
        "    # New! bring outputs back\n",
        "    yHat = yHat.cpu()\n",
        "    y = y.cpu()\n",
        "\n",
        "    # compare the following really long line of code to the training accuracy lines\n",
        "    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )\n",
        "\n",
        "  # end epochs\n",
        "\n",
        "  # function output\n",
        "  return trainAcc,testAcc,losses,net\n",
        "\n",
        "# test the model once to make sure it works\n",
        "trainAcc,testAcc,losses,net = function2trainTheModel(65,2)\n",
        "\n",
        "### run the experiment!\n",
        "#  CPU took 30 mins\n",
        "#  GPU takes 13 mins\n",
        "\n",
        "# define the model parameters\n",
        "numlayers = range(1,4)           # number of hidden layers\n",
        "numunits  = np.arange(50,251,50) # units per hidden layer\n",
        "\n",
        "# initialize output matrices\n",
        "accuracies  = np.zeros((2,len(numunits),len(numlayers)))\n",
        "\n",
        "# start the experiment!\n",
        "for unitidx in range(len(numunits)):\n",
        "  for layeridx in range(len(numlayers)):\n",
        "\n",
        "    # create and train a fresh model\n",
        "    trainAcc,testAcc,losses,net = function2trainTheModel(numunits[unitidx],numlayers[layeridx])\n",
        "\n",
        "    # store the results (average of final 5 epochs)\n",
        "    accuracies[0,unitidx,layeridx] = np.mean(trainAcc[-5:])\n",
        "    accuracies[1,unitidx,layeridx] = np.mean(testAcc[-5:])\n",
        "\n",
        "    # print a friendly status message\n",
        "    print(f'Finished units {unitidx+1}/{len(numunits)} and layers {layeridx+1}/{len(numlayers)}')\n",
        "\n",
        "# show accuracy as a function of model depth\n",
        "fig,ax = plt.subplots(1,2,figsize=(15,6))\n",
        "\n",
        "ax[0].plot(numunits,accuracies[0,:,:],'o-',markerfacecolor='w',markersize=9)\n",
        "ax[1].plot(numunits,accuracies[1,:,:],'o-',markerfacecolor='w',markersize=9)\n",
        "\n",
        "for i in range(2):\n",
        "  ax[i].legend(numlayers)\n",
        "  ax[i].set_ylabel('Accuracy')\n",
        "  ax[i].set_xlabel('Number of hidden units')\n",
        "  ax[i].set_title([ 'Train' if i==0 else 'Test' ][0])\n",
        "\n",
        "plt.show()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "pvVzBzd05nGX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufy2oTHA5m7j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "exPAg6GITEJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NfJGHUpeTEJ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-H8fb1ExTEJ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3MFuOcimTEJ4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cPm_DjNBTEJ5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LrbWAb7tTEJ5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}